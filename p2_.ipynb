{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "path_test = '~/hw2/GAN/output_images'\n",
    "manualSeed=878\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d( 110, 28 * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(28 * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(28 * 8, 28 * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(28 * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d( 28 * 4, 28 * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(28 * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d( 28 * 2, 28, 2, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(28),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d( 28, 3, 2, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(model,outpath,device):\n",
    "    #images.shape : (amount_of_images, 3, 28, 28), type:numpy\n",
    "    \n",
    "    each_imgs = torch.empty((0,3,28,28),device=device)\n",
    "    for cls in range(10):\n",
    "        random.seed(manualSeed)\n",
    "        torch.manual_seed(manualSeed)\n",
    "        cls = torch.full((100,),cls,device=device)\n",
    "        # print(cls)\n",
    "\n",
    "        noise = torch.randn(100, 100, 1, 1, device=device)\n",
    "        # normalize\n",
    "        onehot_label = torch.eye(10,device=device)[cls].view(-1, 10, 1, 1)\n",
    "        noise = torch.cat((noise,onehot_label),dim=1)\n",
    "        \n",
    "        images = model(noise)\n",
    "        each_imgs = torch.cat((each_imgs,images),dim=0)\n",
    "\n",
    "    each_imgs = each_imgs.cpu().detach().numpy()\n",
    "    # output amt = ncls * each_image_amout images\n",
    "\n",
    "    # transpose shape to output image(amt, 3, 28, 28) ->(amt, 28, 28, 3)\n",
    "    imgs_for_output = np.transpose(each_imgs,(0,2,3,1))\n",
    "    imgs_for_output = ((imgs_for_output+1)*127.5).astype(np.uint8)\n",
    "\n",
    "    \n",
    "    for i,ele in enumerate(imgs_for_output):\n",
    "        #shape i = (28,28,3)\n",
    "        imageio.imsave(os.path.join(outpath,\"{}_{:0>3d}.png\".format(i//100,i%100+1)),\n",
    "                        ele.astype(np.uint8))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '~/hw2/GAN/output_images'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load('p2.pth', map_location=device).to(device)\n",
    "output(model,output_path,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
